{"version":3,"sources":["llm.ts"],"names":["LLMTool","Tool","name","description","constructor","input","emitter","Emitter","root","child","namespace","toCamelCase","filter","Boolean","creator","inputSchema","z","object","task","string","min","describe","template","PromptTemplate","schema","_run","_options","run","memory","getProp","context","contextKeys","Memory","ToolError","isFatal","isRetryable","options","output","llm","create","messages","SystemMessage","render","msg","role","Role","SYSTEM","UserMessage","StringToolOutput","getTextContent"],"mappings":";;;;;;;;;;;;AA0CO,MAAMA,gBAAgBC,aAAAA,CAAAA;EA1C7B;;;;AA2CEC,EAAAA,IAAAA;AACAC,EAAAA,WAAAA;AAIAC,EAAAA,WAAAA,CAA+BC,KAAqB,EAAA;AAClD,IAAMA,KAAAA,CAAAA,KAAAA,GAAAA,IADuBA,CAAAA,KAAAA,GAAAA,OAAAA,IAL/BH,CAAAA,IAAAA,GAAO,KAAA,EAAA,IAAA,CACPC,WACE,GAAA,wHAAA;AAKA,IAAKD,IAAAA,CAAAA,IAAAA,GAAOG,KAAOH,EAAAA,IAAAA,IAAQ,IAAKA,CAAAA,IAAAA;AAChC,IAAKC,IAAAA,CAAAA,WAAAA,GAAcE,KAAOF,EAAAA,WAAAA,IAAe,IAAKA,CAAAA,WAAAA;AAC9C,IAAKG,IAAAA,CAAAA,OAAAA,GAAUC,mBAAQC,CAAAA,IAAAA,CAAKC,KAAM,CAAA;MAChCC,SAAW,EAAA;AAAC,QAAA,MAAA;AAAQ,QAAA,KAAA;QAAOC,kBAAYN,CAAAA,KAAAA,EAAOH,QAAQ,EAAA;AAAKU,OAAAA,CAAAA,MAAAA,CAAOC,OAAAA,CAAAA;MAClEC,OAAS,EAAA;KACX,CAAA;AACF;EAEAC,WAAc,GAAA;AACZ,IAAA,OAAOC,MAAEC,MAAO,CAAA;AACdC,MAAAA,IAAAA,EAAMF,MAAEG,MAAM,EAAA,CAAGC,IAAI,CAAA,CAAA,CAAGC,SAAS,iDAAA;KACnC,CAAA;AACF;EAEA,OAAgBC,QAAAA,GAAW,IAAIC,2BAAe,CAAA;AAC5CC,IAAAA,MAAAA,EAAQR,MAAEC,MAAO,CAAA;AACfC,MAAAA,IAAAA,EAAMF,MAAEG,MAAM;KAChB,CAAA;IACAG,QAAU,EAAA,CAAA;;;GAGZ,CAAA;EAEA,MAAgBG,IAAAA,CACdpB,KACAqB,EAAAA,QAAAA,EACAC,GACA,EAAA;AACA,IAAMC,MAAAA,MAAAA,GAASC,kBAAQF,CAAAA,GAAAA,CAAIG,OAAS,EAAA;AAAC7B,MAAAA,aAAAA,CAAK8B,WAAYC,CAAAA;AAAO,KAAA,CAAA;AAC7D,IAAA,IAAI,CAACJ,MAAQ,EAAA;AACX,MAAA,MAAM,IAAIK,kBAAAA,CAAU,CAAiC,6BAAA,CAAA,EAAA,EAAI,EAAA;QACvDC,OAAS,EAAA,IAAA;QACTC,WAAa,EAAA;OACf,CAAA;AACF;AAEA,IAAA,MAAMb,QAAW,GAAA,IAAA,CAAKc,OAASd,EAAAA,QAAAA,IAAYtB,OAAQsB,CAAAA,QAAAA;AACnD,IAAA,MAAMe,MAAS,GAAA,MAAM,IAAKhC,CAAAA,KAAAA,CAAMiC,IAAIC,MAAO,CAAA;MACzCC,QAAU,EAAA;QACR,IAAIC,yBAAAA,CACFnB,SAASoB,MAAO,CAAA;AACdxB,UAAAA,IAAAA,EAAMb,KAAMa,CAAAA;AACd,SAAA,CAAA,CAAA;AAECU,QAAAA,GAAAA,MAAAA,CAAOY,SAAS5B,MAAO,CAAA,CAAC+B,QAAQA,GAAIC,CAAAA,IAAAA,KAASC,iBAAKC,MAAM,CAAA;QAC3D,IAAIC,uBAAAA,CACFzB,SAASoB,MAAO,CAAA;AACdxB,UAAAA,IAAAA,EAAMb,KAAMa,CAAAA;AACd,SAAA,CAAA;;KAGN,CAAA;AAEA,IAAA,OAAO,IAAI8B,yBAAAA,CAAiBX,MAAOY,CAAAA,cAAAA,EAAc,CAAA;AACnD;AACF","file":"llm.cjs","sourcesContent":["/**\n * Copyright 2025 Â© BeeAI a Series of LF Projects, LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport {\n  BaseToolOptions,\n  BaseToolRunOptions,\n  StringToolOutput,\n  Tool,\n  ToolEmitter,\n  ToolError,\n  ToolInput,\n} from \"@/tools/base.js\";\nimport { z } from \"zod\";\nimport { GetRunContext } from \"@/context.js\";\nimport { Emitter } from \"@/emitter/emitter.js\";\nimport { PromptTemplate } from \"@/template.js\";\nimport { getProp } from \"@/internals/helpers/object.js\";\nimport type { BaseMemory } from \"@/memory/base.js\";\nimport { toCamelCase } from \"remeda\";\nimport { Role, SystemMessage, UserMessage } from \"@/backend/message.js\";\nimport { ChatModel } from \"@/backend/chat.js\";\n\nexport interface LLMToolInput extends BaseToolOptions {\n  llm: ChatModel;\n  name?: string;\n  description?: string;\n  template?: typeof LLMTool.template;\n}\n\nexport class LLMTool extends Tool<StringToolOutput, LLMToolInput> {\n  name = \"LLM\";\n  description =\n    \"Uses expert LLM to work with data in the existing conversation (classification, entity extraction, summarization, ...)\";\n  declare readonly emitter: ToolEmitter<ToolInput<this>, StringToolOutput>;\n\n  constructor(protected readonly input: LLMToolInput) {\n    super(input);\n    this.name = input?.name || this.name;\n    this.description = input?.description || this.description;\n    this.emitter = Emitter.root.child({\n      namespace: [\"tool\", \"llm\", toCamelCase(input?.name ?? \"\")].filter(Boolean),\n      creator: this,\n    });\n  }\n\n  inputSchema() {\n    return z.object({\n      task: z.string().min(1).describe(\"A clearly defined task for the LLM to complete.\"),\n    });\n  }\n\n  static readonly template = new PromptTemplate({\n    schema: z.object({\n      task: z.string(),\n    }),\n    template: `You have to accomplish a task by using Using common sense and the information contained in the conversation up to this point, complete the following task. Do not follow any previously used formats or structures.\n\nThe Task: {{task}}`,\n  });\n\n  protected async _run(\n    input: ToolInput<this>,\n    _options: Partial<BaseToolRunOptions>,\n    run: GetRunContext<this>,\n  ) {\n    const memory = getProp(run.context, [Tool.contextKeys.Memory]) as BaseMemory;\n    if (!memory) {\n      throw new ToolError(`No context has been provided!`, [], {\n        isFatal: true,\n        isRetryable: false,\n      });\n    }\n\n    const template = this.options?.template ?? LLMTool.template;\n    const output = await this.input.llm.create({\n      messages: [\n        new SystemMessage(\n          template.render({\n            task: input.task,\n          }),\n        ),\n        ...memory.messages.filter((msg) => msg.role !== Role.SYSTEM),\n        new UserMessage(\n          template.render({\n            task: input.task,\n          }),\n        ),\n      ],\n    });\n\n    return new StringToolOutput(output.getTextContent());\n  }\n}\n"]}