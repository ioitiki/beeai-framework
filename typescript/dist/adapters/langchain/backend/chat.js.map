{"version":3,"sources":["chat.ts"],"names":["LangChainChatModel","ChatModel","emitter","constructor","lcLLM","parameters","Emitter","root","child","namespace","creator","modelId","_modelType","providerId","_create","input","run","preparedInput","prepareInput","response","bindTools","tools","invoke","messages","options","prepareOutput","_createStream","stream","chunk","map","msg","role","content","type","runId","stop","stopSequences","signal","tool_choice","toolChoice","output","push","AssistantMessage","message","text","image_url","toString","ValueError","usage","totalTokens","usage_metadata","total_tokens","promptTokens","input_tokens","completionTokens","output_tokens","response_metadata","stop_sequence","ChatModelOutput","_createStructure","raw","parsed","withStructuredOutput","schema","method","strict","includeRaw","object","createSnapshot","loadSnapshot","snapshot","Object","assign"],"mappings":";;;;;;;AAqCO,MAAMA,2BAA2BC,SAAAA,CAAAA;EArCxC;;;;;AAsCkBC,EAAAA,OAAAA;EAEhBC,WACqBC,CAAAA,KAAAA,EACHC,UAAkC,GAAA,EAClD,EAAA;AACA,IAAA,KAAA,EAAK,EAAA,IAAA,CAHcD,KAAAA,GAAAA,KAAAA,EAAAA,KACHC,UAAAA,GAAAA,UAAAA;AAGhB,IAAKH,IAAAA,CAAAA,OAAAA,GAAUI,OAAQC,CAAAA,IAAAA,CAAKC,KAAM,CAAA;MAChCC,SAAW,EAAA;AAAC,QAAA,SAAA;AAAW,QAAA,WAAA;AAAa,QAAA;;MACpCC,OAAS,EAAA;KACX,CAAA;AACF;AAEA,EAAA,IAAIC,OAAkB,GAAA;AACpB,IAAO,OAAA,IAAA,CAAKP,MAAMQ,UAAU,EAAA;AAC9B;AAEA,EAAA,IAAIC,UAAa,GAAA;AACf,IAAO,OAAA,WAAA;AACT;EAEA,MAAgBC,OAAAA,CAAQC,OAAuBC,GAAiD,EAAA;AAC9F,IAAA,MAAMC,aAAgB,GAAA,IAAA,CAAKC,YAAaH,CAAAA,KAAAA,EAAOC,GAAAA,CAAAA;AAC/C,IAAMG,MAAAA,QAAAA,GAAW,IAAKf,CAAAA,KAAAA,CAAMgB,SACxB,GAAA,MAAM,IAAKhB,CAAAA,KAAAA,CACRgB,SAAUL,CAAAA,KAAAA,CAAMM,KAAS,IAAA,EAAE,CAAA,CAC3BC,OAAOL,aAAcM,CAAAA,QAAAA,EAAUN,aAAcO,CAAAA,OAAO,CACvD,GAAA,MAAM,IAAKpB,CAAAA,KAAAA,CAAMkB,MAAOL,CAAAA,aAAAA,CAAcM,QAAUN,EAAAA,aAAAA,CAAcO,OAAO,CAAA;AAEzE,IAAO,OAAA,IAAA,CAAKC,cAAcN,QAAAA,CAAAA;AAC5B;EAEA,OAAiBO,aAAAA,CACfX,OACAC,GACiC,EAAA;AACjC,IAAA,MAAMC,aAAgB,GAAA,IAAA,CAAKC,YAAaH,CAAAA,KAAAA,EAAOC,GAAAA,CAAAA;AAE/C,IAAMW,MAAAA,MAAAA,GAAS,IAAKvB,CAAAA,KAAAA,CAAMgB,SACtB,GAAA,MAAM,IAAKhB,CAAAA,KAAAA,CACRgB,SAAUL,CAAAA,KAAAA,CAAMM,KAAS,IAAA,EAAE,CAAA,CAC3BM,OAAOV,aAAcM,CAAAA,QAAAA,EAAUN,aAAcO,CAAAA,OAAO,CACvD,GAAA,MAAM,IAAKpB,CAAAA,KAAAA,CAAMuB,MAAOV,CAAAA,aAAAA,CAAcM,QAAUN,EAAAA,aAAAA,CAAcO,OAAO,CAAA;AAEzE,IAAA,WAAA,MAAiBL,YAAYQ,MAAQ,EAAA;AACnC,MAAMC,MAAAA,KAAAA,GAAQ,IAAKH,CAAAA,aAAAA,CAAcN,QAAAA,CAAAA;AACjC,MAAMS,MAAAA,KAAAA;AACR;AACF;AAEUV,EAAAA,YAAAA,CAAaH,OAAuBC,GAAuB,EAAA;AACnE,IAAA,MAAMO,QAA8BR,GAAAA,KAAAA,CAAMQ,QAASM,CAAAA,GAAAA,CAAI,CAACC,GAAS,MAAA;AAC/DC,MAAAA,IAAAA,EAAMD,GAAIC,CAAAA,IAAAA;AACVC,MAAAA,OAAAA,EAASF,GAAIE,CAAAA,OAAAA;AACbC,MAAAA,IAAAA,EAAMH,GAAIC,CAAAA;KAEZ,CAAA,CAAA;AAEA,IAAA,MAAMP,OAAoC,GAAA;AACxCU,MAAAA,KAAAA,EAAOlB,GAAIkB,CAAAA,KAAAA;AACXC,MAAAA,IAAAA,EAAMpB,KAAMqB,CAAAA,aAAAA;AACZC,MAAAA,MAAAA,EAAQrB,GAAIqB,CAAAA,MAAAA;AACZC,MAAAA,WAAAA,EAAavB,KAAMwB,CAAAA;AACrB,KAAA;AAEA,IAAO,OAAA;AAAEhB,MAAAA,QAAAA;AAAUC,MAAAA;AAAQ,KAAA;AAC7B;AAEUC,EAAAA,aAAAA,CAAce,MAAwB,EAAA;AAC9C,IAAA,MAAMjB,WAAsB,EAAA;AAC5B,IAAI,IAAA,OAAOiB,MAAOR,CAAAA,OAAAA,KAAY,QAAU,EAAA;AACtCT,MAAAA,QAAAA,CAASkB,IAAK,CAAA,IAAIC,gBAAiBF,CAAAA,MAAAA,CAAOR,OAAO,CAAA,CAAA;KAC5C,MAAA;AACLT,MAAAA,QAAAA,CAASkB,KACP,IAAIC,gBAAAA,CACFF,OAAOR,OAAQH,CAAAA,GAAAA,CAAI,CAACc,OAAAA,KAAAA;AAClB,QAAIA,IAAAA,OAAAA,CAAQV,SAAS,MAAQ,EAAA;AAC3B,UAAO,OAAA;YAAEA,IAAM,EAAA,MAAA;AAAQW,YAAAA,IAAAA,EAAMD,OAAQC,CAAAA;AAAK,WAAA;SACjCD,MAAAA,IAAAA,OAAAA,CAAQV,SAAS,WAAa,EAAA;AACvC,UAAO,OAAA;YAAEA,IAAM,EAAA,MAAA;YAAQW,IAAMD,EAAAA,OAAAA,CAAQE,UAAUC,QAAQ;AAAG,WAAA;SACrD,MAAA;AACL,UAAA,MAAM,IAAIC,UAAAA,CAAW,CAAyBJ,sBAAAA,EAAAA,OAAAA,CAAQV,IAAI,CAAG,CAAA,CAAA,CAAA;AAC/D;AACF,OAAA,CAAA,CAAA,CAAA;AAGN;AAEA,IAAA,MAAMe,KAAwB,GAAA;MAC5BC,WAAaT,EAAAA,MAAAA,CAAOU,gBAAgBC,YAAgB,IAAA,CAAA;MACpDC,YAAcZ,EAAAA,MAAAA,CAAOU,gBAAgBG,YAAgB,IAAA,CAAA;MACrDC,gBAAkBd,EAAAA,MAAAA,CAAOU,gBAAgBK,aAAiB,IAAA;AAC5D,KAAA;AAEA,IAAMpB,MAAAA,IAAAA,GAA8BK,MAAOgB,CAAAA,iBAAAA,CAAkBC,aAAiB,IAAA,MAAA;AAE9E,IAAA,OAAO,IAAIC,eAAAA,CAAgBnC,QAAUyB,EAAAA,KAAAA,EAAOb,IAAAA,CAAAA;AAC9C;EAEA,MAAgBwB,gBAAAA,CACd5C,OACAC,GACmC,EAAA;AACnC,IAAA,MAAM,EAAEO,QAAUC,EAAAA,OAAAA,KAAY,IAAKN,CAAAA,YAAAA,CAAaH,OAAOC,GAAAA,CAAAA;AACvD,IAAM,MAAA,EAAE4C,KAAKC,MAAM,EAAA,GAAK,MAAM,IAAKzD,CAAAA,KAAAA,CAChC0D,oBAA0B/C,CAAAA,KAAAA,CAAMgD,MAAQ,EAAA;MACvCC,MAAQ,EAAA,YAAA;MACRC,MAAQ,EAAA,KAAA;MACRC,UAAY,EAAA;KACd,CAAA,CACC5C,MAAOC,CAAAA,QAAAA,EAAUC,OAAAA,CAAAA;AAEpB,IAAO,OAAA;MAAE2C,MAAQN,EAAAA,MAAAA;MAAarB,MAAQ,EAAA,IAAA,CAAKf,cAAcmC,GAAAA;AAAuB,KAAA;AAClF;EAEAQ,cAAiB,GAAA;AACf,IAAO,OAAA;AAAE,MAAA,GAAG,MAAMA,cAAAA,EAAAA;AAAkBlE,MAAAA,OAAAA,EAAS,IAAKA,CAAAA,OAAAA;AAASE,MAAAA,KAAAA,EAAO,IAAKA,CAAAA;AAAM,KAAA;AAC/E;AAEAiE,EAAAA,YAAAA,CAAaC,QAAwD,EAAA;AACnEC,IAAOC,MAAAA,CAAAA,MAAAA,CAAO,MAAMF,QAAAA,CAAAA;AACtB;AACF","file":"chat.js","sourcesContent":["/**\n * Copyright 2025 Â© BeeAI a Series of LF Projects, LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport {\n  ChatModel,\n  ChatModelEmitter,\n  ChatModelFinishReason,\n  ChatModelInput,\n  ChatModelObjectInput,\n  ChatModelObjectOutput,\n  ChatModelOutput,\n  ChatModelParameters,\n  ChatModelUsage,\n} from \"@/backend/chat.js\";\nimport { RunContext } from \"@/context.js\";\nimport { Emitter } from \"@/emitter/emitter.js\";\nimport {\n  BaseChatModel,\n  BaseChatModelCallOptions,\n} from \"@langchain/core/language_models/chat_models\";\nimport { AIMessageChunk, BaseMessageLike } from \"@langchain/core/messages\";\nimport { AssistantMessage, Message } from \"@/backend/message.js\";\nimport { ValueError } from \"@/errors.js\";\n\nexport class LangChainChatModel extends ChatModel {\n  public readonly emitter: ChatModelEmitter;\n\n  constructor(\n    protected readonly lcLLM: BaseChatModel,\n    public readonly parameters: ChatModelParameters = {},\n  ) {\n    super();\n    this.emitter = Emitter.root.child({\n      namespace: [\"backend\", \"langchain\", \"chat\"],\n      creator: this,\n    });\n  }\n\n  get modelId(): string {\n    return this.lcLLM._modelType();\n  }\n\n  get providerId() {\n    return \"langchain\";\n  }\n\n  protected async _create(input: ChatModelInput, run: RunContext<this>): Promise<ChatModelOutput> {\n    const preparedInput = this.prepareInput(input, run);\n    const response = this.lcLLM.bindTools\n      ? await this.lcLLM\n          .bindTools(input.tools ?? [])\n          .invoke(preparedInput.messages, preparedInput.options)\n      : await this.lcLLM.invoke(preparedInput.messages, preparedInput.options);\n\n    return this.prepareOutput(response);\n  }\n\n  protected async *_createStream(\n    input: ChatModelInput,\n    run: RunContext<this>,\n  ): AsyncGenerator<ChatModelOutput> {\n    const preparedInput = this.prepareInput(input, run);\n\n    const stream = this.lcLLM.bindTools\n      ? await this.lcLLM\n          .bindTools(input.tools ?? [])\n          .stream(preparedInput.messages, preparedInput.options)\n      : await this.lcLLM.stream(preparedInput.messages, preparedInput.options);\n\n    for await (const response of stream) {\n      const chunk = this.prepareOutput(response);\n      yield chunk;\n    }\n  }\n\n  protected prepareInput(input: ChatModelInput, run: RunContext<this>) {\n    const messages: BaseMessageLike[] = input.messages.map((msg) => ({\n      role: msg.role,\n      content: msg.content,\n      type: msg.role,\n      // TODO\n    }));\n\n    const options: BaseChatModelCallOptions = {\n      runId: run.runId,\n      stop: input.stopSequences,\n      signal: run.signal,\n      tool_choice: input.toolChoice,\n    };\n\n    return { messages, options };\n  }\n\n  protected prepareOutput(output: AIMessageChunk) {\n    const messages: Message[] = [];\n    if (typeof output.content === \"string\") {\n      messages.push(new AssistantMessage(output.content));\n    } else {\n      messages.push(\n        new AssistantMessage(\n          output.content.map((message) => {\n            if (message.type === \"text\") {\n              return { type: \"text\", text: message.text };\n            } else if (message.type === \"image_url\") {\n              return { type: \"text\", text: message.image_url.toString() };\n            } else {\n              throw new ValueError(`Unknown message type \"${message.type}\"`);\n            }\n          }),\n        ),\n      );\n    }\n\n    const usage: ChatModelUsage = {\n      totalTokens: output.usage_metadata?.total_tokens ?? 0,\n      promptTokens: output.usage_metadata?.input_tokens ?? 0,\n      completionTokens: output.usage_metadata?.output_tokens ?? 0,\n    };\n\n    const stop: ChatModelFinishReason = output.response_metadata.stop_sequence || \"stop\";\n\n    return new ChatModelOutput(messages, usage, stop);\n  }\n\n  protected async _createStructure<T>(\n    input: ChatModelObjectInput<T>,\n    run: RunContext<this>,\n  ): Promise<ChatModelObjectOutput<T>> {\n    const { messages, options } = this.prepareInput(input, run);\n    const { raw, parsed } = await this.lcLLM\n      .withStructuredOutput<any>(input.schema, {\n        method: \"jsonSchema\",\n        strict: false,\n        includeRaw: true,\n      })\n      .invoke(messages, options);\n\n    return { object: parsed as T, output: this.prepareOutput(raw as AIMessageChunk) };\n  }\n\n  createSnapshot() {\n    return { ...super.createSnapshot(), emitter: this.emitter, lcLLM: this.lcLLM };\n  }\n\n  loadSnapshot(snapshot: ReturnType<typeof this.createSnapshot>): void {\n    Object.assign(this, snapshot);\n  }\n}\n"]}